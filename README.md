# DE.practicum
Data enfineering study projects

## Создание витрины данных для RFM-классификации пользователей агрегатора доставки еды
Описание:Создание витрины данных и наполние её данными, для помощи приложению по доставке еды правильно сегментировать целевую аудиторию.

Стек: SQL, PostgreSQL

Выводы:

Определены требования к целевой витрине.
Изучена структура исходных данных.
Подготовлена витрину.
Доработаны представления.

## Оптимизация модели данных интернет-магазина

Описание: Оптимизация нагрузки на хранилище интернет-магазина: миграция данных из большой и неудобной таблицы в отдельные логические таблицы, сбор на их основе витрины данных. 

Стек: SQL, PostgreSQL, Python

Выводы:
1. Данные разложены из одной таблицы по нескольким логическим таблицам.
2. Создано удобное представление данных на основе новых логических таблиц.

## Обновление пайплайна обработки данных 

Описание: Обновление пайплайна обработки данных для интернет-магазина: добавление в витрину данных по отмене заказов и возврату средств, а также рассчет метрики по «возвращаемости клиентов».

Стек: Python, Airflow, S3, SQL, PostgreSQL, REST-API

Выводы:
1. Адаптирован пайплайн: в витрине учтены нужные статусы и обновлен пайплайн с учётом этих статусов. 
2. На основе пайплайна наполнена витрина данных по «возвращаемости клиентов» в разрезе недель. 
3. Перезапущен пайплайн и проведена проверка на наличие дубликатов в витринах.

## Реализация витрины для расчётов выплат курьерам

Описание: Рассчеи суммы выплат курьерам: реализация DWH и ETL-пайплайна для данных. 

Стек: Python, Airflow, MongoDB, SQL, PostgreSQL, REST-API

Выводы:
1. Изучены API системы источника - доставки заказов.
2. Спроектирована структура таблиц для слоёв в хранилище.
3. Реализован DAG.

## Поиск сообществ с высокой конверсией в первое сообщение

Описание: Создание аналитической базы данных, для помощи маркетологам решить задачу: разместить на сторонних сайтах рекламу сообществ с высокой активностью.

Стек: Python, Airflow, S3, SQL, PostgreSQL, Vertica

Выводы:
1. Перенесены из S3 в staging-слой новые данные о входе и выходе пользователей из групп.
2. Созданы таблицы для новых данных в слое постоянного хранения.
3. Перенесены новые данные из staging-области в слой DDS.
4. Рассчитаны конверсионные показатели для десяти самых старых сообществ.


## Обновление хранилища данных для соцсети

Описание: Обновленое структуру Data Lake соцсети и добавление витрины данных, в которых используется информация по координатам действий пользователей. 

Стек: Hadoop, MapReduce, HDFS, Apache Spark

Выводы:
1. Обновлена структура Data Lake.
2. Создана витрина в разрезе пользователей.
3. Создана витрина в разрезе зон.
4. Построена витрина для рекомендации друзей.
5. Автоматизировано обновление витрин.

## Создание DWH с использованием облачных технологий для агрегатора доставки еды

Описание: Используя инструменты Yandex Cloud, создание трех микросервисов обработки данных, с помощью которых построен и наполнен DWH для агрегатора доставки еды.

Стек:  Kubernetes, Yandex Cloud, Docker, Python, SQL, Reids

Выводы:
1. С помощью Kubernetes написан сервис для наполнения слоя с сырыми данными.
2. С помощью Kubernetes написан сервис для наполнения слоя DDS.
3. С помощью Kubernetes написан сервис для наполнения слоя с витринами.

## Аналитика транзакционной активности пользователей

Описание: Сбор данных по транзакционной активности пользователей и настройка обновления таблицы с курсом валют. 

Стек: Python, SQL, Postgre SQL, Airflow

Выводы:
1. Построен пайплайн найполнений staging слоя Vertica данными из PostgreSQL.
2. Построен DAG для обновления данных в слое DDS. 
3. Построен аналитический дашборд. 
